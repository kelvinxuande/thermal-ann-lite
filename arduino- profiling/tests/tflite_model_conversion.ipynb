{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sblS7n3zWCWV"
   },
   "source": [
    "**Copyright 2019 The TensorFlow Authors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rvUzWmoWMH5"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCZBFzjClURz"
   },
   "source": [
    "## Do necessary imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/lite/performance/post_training_quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'thermalModel_groupB' from 'C:\\\\Users\\\\user\\\\Anaconda3\\\\lib\\\\thermalModel_groupB.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import codebase\n",
    "import thermalModel_main as tmm\n",
    "import thermalModel_groupB as tm_gb\n",
    "\n",
    "import importlib\n",
    "importlib.reload(tmm)\n",
    "importlib.reload(tm_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\thermalModel_groupB.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['second'][set_index[index]:set_index[index+1]] = df['second'][set_index[index]:set_index[index+1]] + second_increment[index]\n",
      "C:\\Users\\user\\Anaconda3\\lib\\thermalModel_groupB.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['second'][set_index[index]:] = df['second'][set_index[index]:] + second_increment[index]\n",
      "C:\\Users\\user\\Anaconda3\\lib\\thermalModel_groupB.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['second'][set_index[index]:] = df['second'][set_index[index]:] + seconds_summation[index]\n"
     ]
    }
   ],
   "source": [
    "df = tm_gb.load_csv(filename = 'LDPRF_2097.csv', \n",
    "#                     data_list = ['Program time','Current','Voltage','AhCha','AhDch','Temp'], \n",
    "                    features_list = ['runtime_s','Current','Voltage','AhCha','AhDch','Amb','Temp'], \n",
    "                    mode = 2)\n",
    "\n",
    "df1 = tm_gb.load_csv(filename = 'LDPRF_2098.csv', \n",
    "#                      data_list = ['Program time','Current','Voltage','AhCha','AhDch','Temp'], \n",
    "                     features_list = ['runtime_s','Current','Voltage','AhCha','AhDch','Amb','Temp'], \n",
    "                     mode = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runtime_s</th>\n",
       "      <th>Current</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>AhCha</th>\n",
       "      <th>AhDch</th>\n",
       "      <th>Amb</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>435839.000000</td>\n",
       "      <td>435839.000000</td>\n",
       "      <td>435839.000000</td>\n",
       "      <td>435839.000000</td>\n",
       "      <td>435839.000000</td>\n",
       "      <td>4.358390e+05</td>\n",
       "      <td>435839.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24468.740483</td>\n",
       "      <td>-0.595961</td>\n",
       "      <td>3.775370</td>\n",
       "      <td>126.363856</td>\n",
       "      <td>144.644944</td>\n",
       "      <td>2.579465e+01</td>\n",
       "      <td>34.312581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11440.765250</td>\n",
       "      <td>85.854861</td>\n",
       "      <td>0.091213</td>\n",
       "      <td>72.924632</td>\n",
       "      <td>74.703530</td>\n",
       "      <td>2.402277e-10</td>\n",
       "      <td>2.060416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-177.639340</td>\n",
       "      <td>3.536830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.579465e+01</td>\n",
       "      <td>25.794650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14564.850000</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>3.730960</td>\n",
       "      <td>64.452000</td>\n",
       "      <td>81.299000</td>\n",
       "      <td>2.579465e+01</td>\n",
       "      <td>33.008410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24470.300000</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>3.766810</td>\n",
       "      <td>126.039000</td>\n",
       "      <td>145.061000</td>\n",
       "      <td>2.579465e+01</td>\n",
       "      <td>35.085100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34375.750000</td>\n",
       "      <td>0.019150</td>\n",
       "      <td>3.807290</td>\n",
       "      <td>187.997000</td>\n",
       "      <td>208.479000</td>\n",
       "      <td>2.579465e+01</td>\n",
       "      <td>35.850190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44280.800000</td>\n",
       "      <td>223.268950</td>\n",
       "      <td>4.160100</td>\n",
       "      <td>252.040000</td>\n",
       "      <td>272.253000</td>\n",
       "      <td>2.579465e+01</td>\n",
       "      <td>36.724590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           runtime_s        Current        Voltage          AhCha  \\\n",
       "count  435839.000000  435839.000000  435839.000000  435839.000000   \n",
       "mean    24468.740483      -0.595961       3.775370     126.363856   \n",
       "std     11440.765250      85.854861       0.091213      72.924632   \n",
       "min         0.000000    -177.639340       3.536830       0.000000   \n",
       "25%     14564.850000       0.009580       3.730960      64.452000   \n",
       "50%     24470.300000       0.009580       3.766810     126.039000   \n",
       "75%     34375.750000       0.019150       3.807290     187.997000   \n",
       "max     44280.800000     223.268950       4.160100     252.040000   \n",
       "\n",
       "               AhDch           Amb           Temp  \n",
       "count  435839.000000  4.358390e+05  435839.000000  \n",
       "mean      144.644944  2.579465e+01      34.312581  \n",
       "std        74.703530  2.402277e-10       2.060416  \n",
       "min         0.000000  2.579465e+01      25.794650  \n",
       "25%        81.299000  2.579465e+01      33.008410  \n",
       "50%       145.061000  2.579465e+01      35.085100  \n",
       "75%       208.479000  2.579465e+01      35.850190  \n",
       "max       272.253000  2.579465e+01      36.724590  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do type conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime_s    float64\n",
      "Current      float64\n",
      "Voltage      float64\n",
      "AhCha        float64\n",
      "AhDch        float64\n",
      "Amb          float64\n",
      "Temp         float64\n",
      "dtype: object\n",
      "runtime_s    float32\n",
      "Current      float32\n",
      "Voltage      float32\n",
      "AhCha        float32\n",
      "AhDch        float32\n",
      "Amb          float32\n",
      "Temp         float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_float32 = copy.deepcopy(df).astype('float32')\n",
    "print(df.dtypes)\n",
    "# first optimisation, as required by tf lite\n",
    "print(df_float32.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_float32))\n",
    "df_float32 = df_float32.drop(columns=['runtime_s'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target row and inputs/ outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current   -46.004620\n",
      "Voltage     3.784130\n",
      "AhCha       0.000000\n",
      "AhDch      12.521000\n",
      "Amb        25.794649\n",
      "Temp       27.215540\n",
      "Name: 100, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "test_pdSeries_row = copy.deepcopy(df_float32.iloc[100])\n",
    "print(test_pdSeries_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.float32'>\n",
      "[[-46.00462   3.78413   0.       12.521    25.79465]]\n",
      "27.21554\n"
     ]
    }
   ],
   "source": [
    "input_npArray = test_pdSeries_row[:-1].to_numpy()\n",
    "input_npArray = input_npArray.reshape(5,1).T\n",
    "output_npArray = test_pdSeries_row[-1]\n",
    "print(type(input_npArray))\n",
    "print(type(output_npArray))\n",
    "print(input_npArray)\n",
    "print(output_npArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26.764807]]\n"
     ]
    }
   ],
   "source": [
    "tf_model_32 = tf.keras.models.load_model('DNN_0.1_hybrid_model_1.h5')\n",
    "h5_output = tf_model_32.predict(input_npArray)\n",
    "print(h5_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3h7IcvuOOS4J"
   },
   "source": [
    "## Convert to TensorFlow Lite\n",
    "We now have an acceptably accurate model in-memory. However, to use this with TensorFlow Lite for Microcontrollers, we'll need to convert it into the correct format and download it as a file. To do this, we'll use the [TensorFlow Lite Converter](https://www.tensorflow.org/lite/convert). The converter outputs a file in a special, space-efficient format for use on memory-constrained devices.\n",
    "\n",
    "Since this model is going to be deployed on a microcontroller, we want it to be as tiny as possible! One technique for reducing the size of models is called [quantization](https://www.tensorflow.org/lite/performance/post_training_quantization). It reduces the precision of the model's weights, which saves memory, often without much impact on accuracy. Quantized models also run faster, since the calculations required are simpler.\n",
    "\n",
    "The TensorFlow Lite Converter can apply quantization while it converts the model. In the following cell, we'll convert the model twice: once with quantization, once without:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1muAoUm8lSXL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1720"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the model to the TensorFlow Lite format with float16 quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(tf_model_32)\n",
    "model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"model.tflite\", \"wb\").write(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an interpreter for each model\n",
    "model = tf.lite.Interpreter('model.tflite')\n",
    "\n",
    "# Allocate memory for each model\n",
    "model.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "tflite_model_float16_input_details = model.get_input_details()\n",
    "tflite_model_float16_output_details = model.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26.764809]]\n"
     ]
    }
   ],
   "source": [
    "# Create arrays to store the results\n",
    "tflite_model_float16_predictions = np.empty((1, 1))\n",
    "\n",
    "# Test the TensorFlow Lite model\n",
    "input_shape = tflite_model_float16_input_details[0]['shape'] # same for all\n",
    "output_shape = tflite_model_float16_output_details[0]['shape'] # same for all\n",
    "    \n",
    "# preprocess:\n",
    "input_data = input_npArray\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "\n",
    "model.set_tensor(tflite_model_float16_input_details[0]['index'], input_data)\n",
    "model.invoke()\n",
    "tflite_results = model.get_tensor(tflite_model_float16_output_details[0]['index'])\n",
    "print(tflite_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to a C file\n",
    "The final step in preparing our model for use with TensorFlow Lite for Microcontrollers is to convert it into a C source file. You can see an example of this format in [`hello_world/sine_model_data.cc`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/sine_model_data.cc).\n",
    "\n",
    "To do so, we can use a command line utility named [`xxd`](https://linux.die.net/man/1/xxd). The following cell runs `xxd` on our quantized model and prints the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Desktop\\FYP final analysis\\profiling\\tests\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start linux shell\n",
    "# run: xxd -i model.tflite > model.cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # instead of these official instructions:\n",
    "# !cd $cwd\n",
    "# !bash\n",
    "# !xxd -i model.tflite > model.cc\n",
    "# !cat model.cc"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "create_sine_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
